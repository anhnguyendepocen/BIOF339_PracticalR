<!DOCTYPE html>
<html>
  <head>
    <title>Joins, Split-Apply-Combine &amp; MCPs</title>
    <meta charset="utf-8">
    <meta name="author" content="Abhijit Dasgupta" />
    <meta name="date" content="2018-10-24" />
    <link href="lecture_joins_models2_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="robot.css" type="text/css" />
    <link rel="stylesheet" href="robot-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Joins, Split-Apply-Combine &amp; MCPs
### Abhijit Dasgupta
### October 24, 2018

---




# Goals today 

+ Learn how to join data sets (merging)
+ Split-apply-combine
    + Split a dataset into a list of several datasets
    + Do something to each dataset
    + Put the results back together
+ Use it for 
    + Running tests for many variables
    + Visualizing data with p-value annotation
+ Understand why we need multiple comparison procedures (MCP)
    + Things to think about

???

We need to 

+ put datasets capturing different attributes together to find a complete picture
+ evaluate different attributes to see if they contribute to our understanding
+ hedge our bets to ensure we find 

---
    
# Data

This data set is taken from a breast cancer proteome database available [here](https://www.kaggle.com/piotrgrabo/breastcancerproteomes) and modified for this exercise.

+ Clinical data: [CSV](lecture_joinsmodels2_data/BreastCancer_Clinical.csv)|[XLSX](lecture_joinsmodels2_data/BreastCancer_Clinical.xlsx)
+ Proteome data: [CSV](lecture_joinsmodels2_data/BreastCancer_Expression.csv)|[XLSX](lecture_joinsmodels2_data/BreastCancer_Expression.xlsx)

---
class: inverse, middle, center

# Joins

---

# Putting data sets together

+ Quite often, data on individuals lie in different tables
    - Clinical, demographic and bioinformatic data
--
    - Drug, procedure, and payment data (think Medicare)
--
    - Personal health data across different healthcare entities

---
# Joining data sets

We already talked about `cbind` and `rbind`:

.pull-left[
&lt;span style="text-align:center;"&gt;`cbind`&lt;/span&gt;
&lt;img src="lecture_joinsmodels2_data/addcol.png" width="640" /&gt;
]
.pull-right[
&lt;span style="text-align:center;"&gt;`rbind`&lt;/span&gt;
&lt;img src="lecture_joinsmodels2_data/addrow.png" width="640" /&gt;
]

---
# Joining data sets

.pull-left[
We will talk about more general ways of joining two datasets

We will assume:

1. We have two rectangular data sets (so `data.frame` or `tibble`)
1. There is at least one variable (column) in common, even if they have different names
    - ID number
    - SSN (Social Security number)
    - Identifiable information
]

.pull-right[
&lt;img src="lecture_joinsmodels2_data/merge.png" height="10%"/&gt;
]

---

# Joining data sets

&lt;img width="100%" src="lecture_joinsmodels2_data/joins.png"/&gt;

--

&lt;table width="100%"&gt;
&lt;tr&gt;
&lt;td style="text-align:center;"&gt;inner_join&lt;/td&gt;
&lt;td style="text-align:center;"&gt;left_join&lt;/td&gt;
&lt;td style="text-align:center;"&gt;right_join&lt;/td&gt;
&lt;td style="text-align:center;"&gt;outer_join&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

--

The "join condition" are the common variables in the two datasets, i.e. rows are selected if the values of the common variables in the left dataset matches the values of the common variables in the right dataset

---
## Data example


```r
library(readxl)
clinical &lt;- read_excel('lecture_joinsmodels2_data/BreastCancer_Clinical.xlsx') %&gt;% 
  set_names(str_replace_all(names(.), '[ -]+', '_'))
proteome &lt;- read_excel('lecture_joinsmodels2_data/BreastCancer_Expression.xlsx') %&gt;% 
  set_names(str_replace_all(names(.), '[ -]+', '_'))
```

.pull-left[

```
# A tibble: 105 x 30
   Complete_TCGA_ID Gender Age_at_Initial_Pathologic_… ER_Status PR_Status
   &lt;chr&gt;            &lt;chr&gt;                        &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    
 1 TCGA-A2-A0T2     FEMALE                          66 Negative  Negative 
 2 TCGA-A2-A0CM     FEMALE                          40 Negative  Negative 
 3 TCGA-BH-A18V     FEMALE                          48 Negative  Negative 
 4 TCGA-BH-A18Q     FEMALE                          56 Negative  Negative 
 5 TCGA-BH-A0E0     FEMALE                          38 Negative  Negative 
 6 TCGA-A7-A0CE     FEMALE                          57 Negative  Negative 
 7 TCGA-D8-A142     FEMALE                          74 Negative  Negative 
 8 TCGA-A2-A0D0     FEMALE                          60 Negative  Negative 
 9 TCGA-AO-A0J6     FEMALE                          61 Negative  Negative 
10 TCGA-A2-A0YM     FEMALE                          67 Negative  Negative 
# ... with 95 more rows, and 25 more variables: HER2_Final_Status &lt;chr&gt;,
#   Tumor &lt;chr&gt;, Tumor_T1_Coded &lt;chr&gt;, Node &lt;chr&gt;, Node_Coded &lt;chr&gt;,
#   Metastasis &lt;chr&gt;, Metastasis_Coded &lt;chr&gt;, AJCC_Stage &lt;chr&gt;,
#   Converted_Stage &lt;chr&gt;, Survival_Data_Form &lt;chr&gt;, Vital_Status &lt;chr&gt;,
#   Days_to_Date_of_Last_Contact &lt;dbl&gt;, Days_to_date_of_Death &lt;dbl&gt;,
#   OS_event &lt;dbl&gt;, OS_Time &lt;dbl&gt;, PAM50_mRNA &lt;chr&gt;,
#   SigClust_Unsupervised_mRNA &lt;dbl&gt;, SigClust_Intrinsic_mRNA &lt;dbl&gt;,
#   miRNA_Clusters &lt;dbl&gt;, methylation_Clusters &lt;dbl&gt;, RPPA_Clusters &lt;chr&gt;,
#   CN_Clusters &lt;dbl&gt;, `Integrated_Clusters_(with_PAM50)` &lt;dbl&gt;,
#   `Integrated_Clusters_(no_exp)` &lt;dbl&gt;,
#   `Integrated_Clusters_(unsup_exp)` &lt;dbl&gt;
```
]
.pull-right[

```
# A tibble: 83 x 11
   TCGA_ID     NP_958782 NP_958785 NP_958786 NP_000436 NP_958781 NP_958780
   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
 1 TCGA-AO-A1…     1.10      1.11      1.11      1.11      1.12      1.11 
 2 TCGA-C8-A1…     2.61      2.65      2.65      2.65      2.65      2.65 
 3 TCGA-AO-A1…    -0.660    -0.649    -0.654    -0.632    -0.640    -0.654
 4 TCGA-BH-A1…     0.195     0.215     0.215     0.205     0.215     0.215
 5 TCGA-C8-A1…    -0.494    -0.504    -0.501    -0.510    -0.504    -0.504
 6 TCGA-C8-A1…     2.77      2.78      2.78      2.80      2.79      2.78 
 7 TCGA-E2-A1…     0.863     0.870     0.870     0.866     0.870     0.870
 8 TCGA-C8-A1…     1.41      1.41      1.41      1.41      1.41      1.41 
 9 TCGA-A2-A0…     1.19      1.19      1.19      1.19      1.20      1.19 
10 TCGA-AO-A1…     1.10      1.10      1.10      1.10      1.09      1.10 
# ... with 73 more rows, and 4 more variables: NP_958783 &lt;dbl&gt;,
#   NP_958784 &lt;dbl&gt;, NP_112598 &lt;dbl&gt;, NP_001611 &lt;dbl&gt;
```

]

---
## Data example


```r
library(readxl)
clinical &lt;- read_excel('lecture_joinsmodels2_data/BreastCancer_Clinical.xlsx') %&gt;% 
  set_names(str_replace_all(names(.), '[ -]+', '_'))
proteome &lt;- read_excel('lecture_joinsmodels2_data/BreastCancer_Expression.xlsx') %&gt;% 
  set_names(str_replace_all(names(.), '[ -]+', '_'))
```

.pull-left[

```
# A tibble: 105 x 2
   Complete_TCGA_ID Gender
   &lt;chr&gt;            &lt;chr&gt; 
 1 TCGA-A2-A0T2     FEMALE
 2 TCGA-A2-A0CM     FEMALE
 3 TCGA-BH-A18V     FEMALE
 4 TCGA-BH-A18Q     FEMALE
 5 TCGA-BH-A0E0     FEMALE
 6 TCGA-A7-A0CE     FEMALE
 7 TCGA-D8-A142     FEMALE
 8 TCGA-A2-A0D0     FEMALE
 9 TCGA-AO-A0J6     FEMALE
10 TCGA-A2-A0YM     FEMALE
# ... with 95 more rows
```
]
.pull-right[

```
# A tibble: 83 x 2
   TCGA_ID      NP_958782
   &lt;chr&gt;            &lt;dbl&gt;
 1 TCGA-AO-A12D     1.10 
 2 TCGA-C8-A131     2.61 
 3 TCGA-AO-A12B    -0.660
 4 TCGA-BH-A18Q     0.195
 5 TCGA-C8-A130    -0.494
 6 TCGA-C8-A138     2.77 
 7 TCGA-E2-A154     0.863
 8 TCGA-C8-A12L     1.41 
 9 TCGA-A2-A0EX     1.19 
10 TCGA-AO-A12D     1.10 
# ... with 73 more rows
```
]

--

We see that both have the same ID variable, but with different names and different orders

???

Let's keep only the first two columns so we can see the ID variable

---

## Data example

Let's make sure that the ID's are truly IDs, i.e. each row has a unique value


```r
length(unique(clinical$Complete_TCGA_ID)) == nrow(clinical)
```

```
[1] TRUE
```
--


```r
length(unique(proteome$TCGA_ID)) == nrow(proteome)
```

```
[1] FALSE
```


--
&lt;div style="height:25%;margins:auto;"&gt;
&lt;img style="display:block; margin:0 auto; height: 70%;" src="https://twitchy.com/wp-content/uploads/2015/04/screen-shot-2015-04-13-at-2-06-38-pm-300x300.png"/&gt;
&lt;/div&gt;

???

We need the ID variables to be unique for each row. If we use multiple columns to define the "ID" then each row needs to have a unique set of values for those columns. Otherwise the joins get confused about 
which rows go with which rows. 

---
## Data example

For convenience we'll keep the first instance for each ID in the `proteome` data


```r
proteome &lt;- proteome %&gt;% filter(!duplicated(TCGA_ID))
```

&gt; `duplicated` = TRUE if a previous row contains the same value

--


```r
length(unique(proteome$TCGA_ID)) == nrow(proteome)
```

```
[1] TRUE
```

---
## Inner join


```r
common_rows &lt;- inner_join(clinical[,1:6], proteome, by=c('Complete_TCGA_ID'='TCGA_ID'))
```

```
# A tibble: 77 x 16
   Complete_TCGA_ID Gender Age_at_Initial_Pathologic_… ER_Status PR_Status
   &lt;chr&gt;            &lt;chr&gt;                        &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    
 1 TCGA-A2-A0CM     FEMALE                          40 Negative  Negative 
 2 TCGA-BH-A18Q     FEMALE                          56 Negative  Negative 
 3 TCGA-A7-A0CE     FEMALE                          57 Negative  Negative 
 4 TCGA-D8-A142     FEMALE                          74 Negative  Negative 
 5 TCGA-AO-A0J6     FEMALE                          61 Negative  Negative 
 6 TCGA-A2-A0YM     FEMALE                          67 Negative  Negative 
 7 TCGA-A2-A0D2     FEMALE                          45 Negative  Negative 
 8 TCGA-A2-A0SX     FEMALE                          48 Negative  Negative 
 9 TCGA-AO-A0JL     FEMALE                          59 Negative  Negative 
10 TCGA-AO-A12F     FEMALE                          36 Negative  Negative 
# ... with 67 more rows, and 11 more variables: HER2_Final_Status &lt;chr&gt;,
#   NP_958782 &lt;dbl&gt;, NP_958785 &lt;dbl&gt;, NP_958786 &lt;dbl&gt;, NP_000436 &lt;dbl&gt;,
#   NP_958781 &lt;dbl&gt;, NP_958780 &lt;dbl&gt;, NP_958783 &lt;dbl&gt;, NP_958784 &lt;dbl&gt;,
#   NP_112598 &lt;dbl&gt;, NP_001611 &lt;dbl&gt;
```

--

Note that we have all the columns from both datasets, but only 77 rows, which is the common set of IDs from the two datasets
--

&gt; If you don't include the `by` option, R will attempt to match values of any columns with the same names

---
## Left join

```r
left_rows &lt;- left_join(clinical[,1:6], proteome, by=c('Complete_TCGA_ID'='TCGA_ID'))
```

```
# A tibble: 105 x 16
  Complete_TCGA_ID Gender Age_at_Initial_Pathologic_Diagnosis ER_Status
  &lt;chr&gt;            &lt;chr&gt;                                &lt;dbl&gt; &lt;chr&gt;    
1 TCGA-A2-A0T2     FEMALE                                  66 Negative 
2 TCGA-A2-A0CM     FEMALE                                  40 Negative 
3 TCGA-BH-A18V     FEMALE                                  48 Negative 
  PR_Status HER2_Final_Status NP_958782 NP_958785 NP_958786 NP_000436
  &lt;chr&gt;     &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 Negative  Negative             NA        NA        NA        NA    
2 Negative  Negative              0.683     0.694     0.698     0.687
3 Negative  Negative             NA        NA        NA        NA    
  NP_958781 NP_958780 NP_958783 NP_958784 NP_112598 NP_001611
      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1    NA        NA        NA        NA         NA       NA    
2     0.687     0.698     0.698     0.698     -2.65    -0.984
3    NA        NA        NA        NA         NA       NA    
# ... with 102 more rows
```

We get 105 rows, which is all the rows of `clinical`, combined with the rows of `proteome` with common IDs. The rest of the rows get `NA` for the proteome columns.

---
## Right join

```r
right_rows &lt;- right_join(clinical[,1:6], proteome, by=c('Complete_TCGA_ID'='TCGA_ID'))
```

```
# A tibble: 80 x 16
  Complete_TCGA_ID Gender Age_at_Initial_Pathologic_Diagnosis ER_Status
  &lt;chr&gt;            &lt;chr&gt;                                &lt;dbl&gt; &lt;chr&gt;    
1 TCGA-AO-A12D     FEMALE                                  43 Negative 
2 TCGA-C8-A131     FEMALE                                  82 Negative 
3 TCGA-AO-A12B     FEMALE                                  63 Positive 
  PR_Status HER2_Final_Status NP_958782 NP_958785 NP_958786 NP_000436
  &lt;chr&gt;     &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 Negative  Positive              1.10      1.11      1.11      1.11 
2 Negative  Negative              2.61      2.65      2.65      2.65 
3 Positive  Negative             -0.660    -0.649    -0.654    -0.632
  NP_958781 NP_958780 NP_958783 NP_958784 NP_112598 NP_001611
      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1     1.12      1.11      1.11      1.11     -1.52      0.483
2     2.65      2.65      2.65      2.65      3.91     -1.05 
3    -0.640    -0.654    -0.649    -0.649    -0.618     1.22 
# ... with 77 more rows
```

--

Here we get 80 rows, which is all the rows of `proteome`, along with the rows of `clinical` with common IDs, but with the columns of `clinical` appearing first.

---
## Outer/Full Join


```r
full_rows &lt;- full_join(clinical[,1:6], proteome, by=c('Complete_TCGA_ID'='TCGA_ID'))
```

```
# A tibble: 108 x 16
  Complete_TCGA_ID Gender Age_at_Initial_Pathologic_Diagnosis ER_Status
  &lt;chr&gt;            &lt;chr&gt;                                &lt;dbl&gt; &lt;chr&gt;    
1 TCGA-A2-A0T2     FEMALE                                  66 Negative 
2 TCGA-A2-A0CM     FEMALE                                  40 Negative 
3 TCGA-BH-A18V     FEMALE                                  48 Negative 
  PR_Status HER2_Final_Status NP_958782 NP_958785 NP_958786 NP_000436
  &lt;chr&gt;     &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 Negative  Negative             NA        NA        NA        NA    
2 Negative  Negative              0.683     0.694     0.698     0.687
3 Negative  Negative             NA        NA        NA        NA    
  NP_958781 NP_958780 NP_958783 NP_958784 NP_112598 NP_001611
      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1    NA        NA        NA        NA         NA       NA    
2     0.687     0.698     0.698     0.698     -2.65    -0.984
3    NA        NA        NA        NA         NA       NA    
# ... with 105 more rows
```

--

Here we obtain 108 rows and 16 columns. So we've expanded the data in both rows and columns, putting missing values in where needed.

---
# Joins

In each of `inner_join`, `left_join`, `right_join` and `full_join`, the number of columns always increases 

There are also two joins where the number of columns don't increase. They aren't really "joins" in that sense, but really fancy filters on a dataset

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Join &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Use &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Description &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; semi_join &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; semi_join(A,B) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Keep rows in A where ID matches some ID value in B &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; anti_join &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; anti_join(A,B) &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Keep rows in A where ID does NOT match any ID value in B &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

These just filter the rows of `A` without adding any columns of `B`.

---
class: inverse, middle, center

## Are there protein expression differences between ER +ve and ER -ve breast cancers

---

# Create analytic dataset


```r
final_data &lt;- clinical %&gt;% 
  inner_join(proteome, by=c("Complete_TCGA_ID"="TCGA_ID")) %&gt;% 
  filter(Gender =='FEMALE') %&gt;% 
  select(Complete_TCGA_ID, Age_at_Initial_Pathologic_Diagnosis, ER_Status,
         starts_with("NP")) # grabs all the protein data
```

```
# A tibble: 75 x 13
  Complete_TCGA_ID Age_at_Initial_Pathologic_Diagnosis ER_Status NP_958782
  &lt;chr&gt;                                          &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;
1 TCGA-A2-A0CM                                      40 Negative      0.683
2 TCGA-BH-A18Q                                      56 Negative      0.195
3 TCGA-A7-A0CE                                      57 Negative     -1.12 
  NP_958785 NP_958786 NP_000436 NP_958781 NP_958780 NP_958783 NP_958784
      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1     0.694     0.698     0.687     0.687     0.698     0.698     0.698
2     0.215     0.215     0.205     0.215     0.215     0.215     0.215
3    -1.12     -1.12     -1.13     -1.13     -1.12     -1.12     -1.12 
  NP_112598 NP_001611
      &lt;dbl&gt;     &lt;dbl&gt;
1     -2.65    -0.984
2     -1.04    -0.517
3      2.24    -2.58 
# ... with 72 more rows
```

---
## Protein-specific analyses

We want to analyze each protein separately, while maintaining alignment with ER status and age.

--

The R trick is to make this wide table long, so you can split on the rows 


```r
final_data2 &lt;- final_data %&gt;% gather(protein, expression, starts_with('NP')) %&gt;% 
  arrange(Complete_TCGA_ID)
```

```
# A tibble: 750 x 5
  Complete_TCGA_ID Age_at_Initial_Pathologic_Diagnosis ER_Status protein  
  &lt;chr&gt;                                          &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    
1 TCGA-A2-A0CM                                      40 Negative  NP_958782
2 TCGA-A2-A0CM                                      40 Negative  NP_958785
3 TCGA-A2-A0CM                                      40 Negative  NP_958786
  expression
       &lt;dbl&gt;
1      0.683
2      0.694
3      0.698
# ... with 747 more rows
```

---
# Split-apply-combine

&lt;img src="lecture_joinsmodels2_data/split-apply-combine.png" width="2956" /&gt;

---
## Splitting data by protein

There are two ways of doing this:


```r
final_data2_grp &lt;- final_data2 %&gt;% group_by(protein)
```
or

```r
final_data2_nest &lt;- final_data2 %&gt;% nest(-protein)
```

--


```
# A tibble: 10 x 2
   protein   data             
   &lt;chr&gt;     &lt;list&gt;           
 1 NP_958782 &lt;tibble [75 × 4]&gt;
 2 NP_958785 &lt;tibble [75 × 4]&gt;
 3 NP_958786 &lt;tibble [75 × 4]&gt;
 4 NP_000436 &lt;tibble [75 × 4]&gt;
 5 NP_958781 &lt;tibble [75 × 4]&gt;
 6 NP_958780 &lt;tibble [75 × 4]&gt;
 7 NP_958783 &lt;tibble [75 × 4]&gt;
 8 NP_958784 &lt;tibble [75 × 4]&gt;
 9 NP_112598 &lt;tibble [75 × 4]&gt;
10 NP_001611 &lt;tibble [75 × 4]&gt;
```

--

This is an example of a `list-column`. We will actually use this form, since it's a bit clearer to understand

???

We've stored a list within a column, aligned to each protein.

Advantages:

1. Visual ease and alignment
1. Can use `dplyr` verbs along with `purrr` functions

---

&lt;img src="lecture_joinsmodels2_data/split-apply-combine.png" width="2956" /&gt;

???

Now we have to apply some function to each split dataset that will get us the desired result

---
class: inverse, middle, center

# Side note: Functions

---

# Functions

Functions are **rules** written in R code that take some _input_ and give some _output_


```r
#' @param d A data.frame object
#'
#' @return The p-value for the 2-sided t-test comparing expression between ER_Status
my_test &lt;- function(d){
  ttest &lt;- t.test(expression ~ ER_Status, data = d)
  return(ttest$p.value)
}
```

This function takes in a `data.frame`, does some operations on it (runs a t-test, and extracts the p-value) and returns a value (the p-value).

&gt; In general, a function can output any kind of R object. We'll learn by example, but for more details, see [this chapter](http://r4ds.had.co.nz/functions.html) in 
_R for Data Science_ by Wickham &amp; Grolemund.

We will **apply** this function to each split dataset in `final_data2_nest`

---


```
# A tibble: 10 x 2
   protein   data             
   &lt;chr&gt;     &lt;list&gt;           
 1 NP_958782 &lt;tibble [75 × 4]&gt;
 2 NP_958785 &lt;tibble [75 × 4]&gt;
 3 NP_958786 &lt;tibble [75 × 4]&gt;
 4 NP_000436 &lt;tibble [75 × 4]&gt;
 5 NP_958781 &lt;tibble [75 × 4]&gt;
 6 NP_958780 &lt;tibble [75 × 4]&gt;
 7 NP_958783 &lt;tibble [75 × 4]&gt;
 8 NP_958784 &lt;tibble [75 × 4]&gt;
 9 NP_112598 &lt;tibble [75 × 4]&gt;
10 NP_001611 &lt;tibble [75 × 4]&gt;
```

Let's take a look at an element in the `data` column

```r
final_data2_nest$data[[1]]
```

```
# A tibble: 75 x 4
  Complete_TCGA_ID Age_at_Initial_Pathologic_Diagnosis ER_Status
  &lt;chr&gt;                                          &lt;dbl&gt; &lt;chr&gt;    
1 TCGA-A2-A0CM                                      40 Negative 
2 TCGA-A2-A0D2                                      45 Negative 
3 TCGA-A2-A0EQ                                      64 Negative 
  expression
       &lt;dbl&gt;
1      0.683
2      0.107
3     -0.913
# ... with 72 more rows
```

---

## Applying a function to each split dataset

We will use the function `purrr::map` to do this:


```r
final_data2_nest %&gt;% mutate(pval = map(data, my_test))
```

```
# A tibble: 10 x 3
   protein   data              pval     
   &lt;chr&gt;     &lt;list&gt;            &lt;list&gt;   
 1 NP_958782 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
 2 NP_958785 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
 3 NP_958786 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
 4 NP_000436 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
 5 NP_958781 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
 6 NP_958780 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
 7 NP_958783 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
 8 NP_958784 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
 9 NP_112598 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
10 NP_001611 &lt;tibble [75 × 4]&gt; &lt;dbl [1]&gt;
```

---
&lt;img src="lecture_joinsmodels2_data/split-apply-combine.png" width="2956" /&gt;

???

Now we have to combine the results so that each protein gets a corresponding p-value

---

## Combining the split results


```r
final_data2_nest %&gt;% mutate(pval = map(data, my_test)) %&gt;% 
  mutate(pval = unlist(pval))
```

```
# A tibble: 10 x 3
   protein   data                  pval
   &lt;chr&gt;     &lt;list&gt;               &lt;dbl&gt;
 1 NP_958782 &lt;tibble [75 × 4]&gt; 0.924   
 2 NP_958785 &lt;tibble [75 × 4]&gt; 0.934   
 3 NP_958786 &lt;tibble [75 × 4]&gt; 0.940   
 4 NP_000436 &lt;tibble [75 × 4]&gt; 0.922   
 5 NP_958781 &lt;tibble [75 × 4]&gt; 0.926   
 6 NP_958780 &lt;tibble [75 × 4]&gt; 0.930   
 7 NP_958783 &lt;tibble [75 × 4]&gt; 0.931   
 8 NP_958784 &lt;tibble [75 × 4]&gt; 0.931   
 9 NP_112598 &lt;tibble [75 × 4]&gt; 0.908   
10 NP_001611 &lt;tibble [75 × 4]&gt; 0.000432
```

--

This could be done in one operation, as well

```r
final_data2_nest %&gt;% mutate(pval = map_dbl(data, my_test))
```

---

# What's `map` doing?


```r
final_data2_nest %&gt;% mutate(pval = map_dbl(data, my_test)) %&gt;% head(3)
```

```
# A tibble: 3 x 3
  protein   data               pval
  &lt;chr&gt;     &lt;list&gt;            &lt;dbl&gt;
1 NP_958782 &lt;tibble [75 × 4]&gt; 0.924
2 NP_958785 &lt;tibble [75 × 4]&gt; 0.934
3 NP_958786 &lt;tibble [75 × 4]&gt; 0.940
```

--


```r
my_test(final_data2_nest$data[[1]])
```

```
[1] 0.9238144
```

--


```r
my_test(final_data2_nest$data[[2]])
```

```
[1] 0.9340165
```

---
# The `map` function

1. **`map(data, my_test)`**:
    - `data` is a list of data.frames, and `my_test` is a function that takes a data.frame as input and produces some output, that is stored in a list
1. **`map(data, ~t.test(expression ~ ER_Status, data = .))`**: 
    - Apply an anonymous function to each element of `data`, where the `.` serves as a place holder for an element of `data`. The anonymous function must start with a `~`. Note that the result of the anonymous function is the output of a `t.test`, which is a kind of object in R
1. **`map(data, "ER_Status")`**: 
    - Extract the element `ER_Status` from each element of `data`

---
## Pipelining this process


```r
final_data2 %&gt;% nest(-protein) %&gt;% 
  mutate(test = map(data,  ~t.test(expression ~ ER_Status, data = .))) %&gt;% 
  mutate(pval = map_dbl(test, 'p.value')) %&gt;% head(3)
```

```
# A tibble: 3 x 4
  protein   data              test         pval
  &lt;chr&gt;     &lt;list&gt;            &lt;list&gt;      &lt;dbl&gt;
1 NP_958782 &lt;tibble [75 × 4]&gt; &lt;S3: htest&gt; 0.924
2 NP_958785 &lt;tibble [75 × 4]&gt; &lt;S3: htest&gt; 0.934
3 NP_958786 &lt;tibble [75 × 4]&gt; &lt;S3: htest&gt; 0.940
```

--

Cleaning it up


```r
final_data2 %&gt;% nest(-protein) %&gt;% 
  mutate(test = map(data,  ~t.test(expression ~ ER_Status, data = .))) %&gt;% 
  mutate(pval = map_dbl(test, 'p.value')) %&gt;% 
* select(protein, pval) %&gt;% head(3)
```

```
# A tibble: 3 x 2
  protein    pval
  &lt;chr&gt;     &lt;dbl&gt;
1 NP_958782 0.924
2 NP_958785 0.934
3 NP_958786 0.940
```



---
class: inverse, middle, center

# Multiple comparison procedures (MCP)

---

## Why do we need it?

+ Recall, in hypothesis tests, the Type I error (or false positive rate) is 
`$$\Pr(Reject\ H_0 | H_0\ is\ true)$$`
This is typically limited by the testing procedure to 5%.  
    - For the more technically interested, this is from the _Neyman-Pearson lemma_
+ There is always a chance we are wrong!!

---

## Why do we need it?

Imagine your test is like a biased coin, with heads being "Reject `\(H_0\)`" and tails being "Do not reject `\(H_0\)`"

Now assume `\(H_0\)` is true, and you're doing multiple tests using the same data

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Number of tests &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Coin tosses &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Pr(at least one head) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 toss &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.05 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 2 tosses &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 5 tosses &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.23 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 10 tosses &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.40 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 100 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 100 tosses &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.99 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1,000,000 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1 million tosses &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.00 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

This means, if you're doing 1 million tests (like, e.g., a GWAS), the chance that you 
get **at least one false positive** is practically 1, i.e. a sure shot.

---

## Bonferroni correction

If you have _n_ tests using the same data, then make sure that the Type I error is `\(0.05/n\)`. This means that for 100 tests, we'd reject the null hypothesis if the p-value was less than 0.0005 rather than 0.05.

How does this help?

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Number of tests &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Nominal FP rate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Corrected FP rate &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.050 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.050 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.098 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.226 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.401 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 100 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.994 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1000000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

The FP rate is the probability of getting at least one false positive. 

--

Realize that this is quite stringent, since we're not allowing any false positives.

---

# Bonferroni correction

There is a price to pay for this stringency, in terms of 

&gt; Statistical Power = Pr(Reject `\(H_0\)` | `\(H_0\)` is FALSE)
&gt;
&gt; This is usually set at 80%

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Number of tests &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Nominal FP rate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Bonferroni-corrected FP rate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Statistical power &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.050 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.050 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.800 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.098 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.706 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.226 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.573 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.401 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.474 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 100 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.994 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.212 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.076 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 10000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.023 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 100000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.006 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1000000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.000 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.049 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.001 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightLanguage": "R",
"countIncrementalSlides": false,
"highlightStyle": "zenburn",
"highlightLines": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
